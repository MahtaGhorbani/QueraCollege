{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## اضافه کردن کتابخانه‌های مورد نیاز"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.metrics as metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## خواندن داده\n",
    "به عنوان مثالی از مسئله دسته‌بندی دوتایی، از داده‌های سرطان استفاده می‌کنیم که پیش‌بینی مدل در مورد آنها خوش‌خیم/بدخیم بودن است."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "wbc = pd.read_csv('wbc.csv',index_col='id')\n",
    "y= wbc['diagnosis'].map({'B':0,'M':1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "زیر مجموعه‌ای از کل ویژگی‌های موجود در داده (در اینجا میانگین شاخص‌های مختلف یک تومور) را به عنوان ورودی مدل جدا می‌کنیم"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols =wbc.columns[wbc.columns.str.endswith('mean')]\n",
    "x = wbc[cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "داده را به دو بخش\n",
    "`train`\n",
    "و\n",
    "`test`\n",
    "تقسیم می‌کنیم و یک درخت تصمیم به عنوان مدل دسته‌بندی روی داده‌های `train`، برازش می‌کنیم."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc = DecisionTreeClassifier(min_samples_leaf=3,max_depth=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x,y,stratify = y , test_size= 0.2,random_state = 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=8,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=3, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtc.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted = dtc.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## سنجش مدل\n",
    "حالا پس از گرفتن خروجی مدل برای داده‌های آزمون، می‌توانیم آن را برای کلاس ۱ از طریق شاخص های مختلفی با خروجی درست مقایسه کنیم و به آن امتیاز دهیم. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Confusion Matrix](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html#sklearn.metrics.confusion_matrix)\n",
    "به این شکل می‌توانید ماتریس در هم ریختگی را برای این مجموعه از پیش‌بینی‌ها محاسبه کنید.\n",
    "- برای حالتی که بیشتر از دو کلاس در خروجی داریم، یک محور ماتریس در‌هم‌ریختگی کلاس پیش‌بینی شده و محور دیگر آن، کلاس واقعی یک متغیر خواهد بود. مثلا اگر این ماتریس را $C_{n \\times n}$ و تعداد کلاس‌ها را $n$ در نظر بگیریم، $C_{ij}$ برابر تعداد داده‌هایی خواهد بود که واقعا در کلاس $i$ قرار دارند ولی در کلاس $j$ پیش‌بینی شده‌اند."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[69,  3],\n",
       "       [ 9, 33]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(y_test,y_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Accuracy](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html#sklearn.metrics.accuracy_score)\n",
    "$$\n",
    "Accuracy = \\frac{TP+TN}{(TP+FP+FN+TN)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8947368421052632"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(y_test,y_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Precision](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_score.html#sklearn.metrics.precision_score)\n",
    "$$\n",
    "Precision = \\frac{TP}{TP+FP}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9166666666666666"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.precision_score(y_test,y_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Recall](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.recall_score.html#sklearn.metrics.recall_score)\n",
    "$$\n",
    "Recall = \\frac{TP}{TP+FN}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7857142857142857"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.recall_score(y_test,y_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [F-1 Score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html#sklearn.metrics.f1_score)\n",
    "$$\n",
    "F1 = \\frac{2}{Recall^{-1} + Precision^{-1}} =  2 \\frac{Recall*Precision}{Recall + Precision}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8461538461538461"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.f1_score(y_test,y_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Classification Report](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html#sklearn.metrics.classification_report)\n",
    "چون این چند شاخص ذکر شده در اکثر مسئله‌های دسته‌بندی(*Classification*) به کار می‌آیند، می‌توانید با استفاده از این متد همه را یکجا داشته باشید.\n",
    "- هرکدام از این شاخص‌ها (*Precision* , *Recall* , *Accuracy* , ...) برای هر کدام از کلاس‌های خروجی تعریف می‌شوند ولی بسته به اینکه کدام کلاس برای ما اهمیت دارد، استفاده می‌شوند."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.96      0.92        72\n",
      "           1       0.92      0.79      0.85        42\n",
      "\n",
      "    accuracy                           0.89       114\n",
      "   macro avg       0.90      0.87      0.88       114\n",
      "weighted avg       0.90      0.89      0.89       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test,y_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
